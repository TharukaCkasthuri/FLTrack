{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f511941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from FLTrack.models import ShallowNN\n",
    "from FLTrack.evals import evaluate_mae_with_confidence\n",
    "from FLTrack.evals import influence\n",
    "from FLTrack.evals import evaluate\n",
    "from FLTrack.evals import euclidean_distance, accumulated_proximity, hessian_eccentricity\n",
    "\n",
    "features = 169\n",
    "batch_size = 64\n",
    "loss_fn = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837ad7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = [f\"c{i}\" for i in range(1, 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef71a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loss_fn, dataloader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model with validation dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    model: torch.nn.Module object; model to be evaluated\n",
    "    loss_fn: torch.nn.Module object; loss function\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    loss_avg: float; average loss\n",
    "    \"\"\"\n",
    "    batch_loss = []\n",
    "    for _, (x, y) in enumerate(dataloader):\n",
    "        outputs = model(x)\n",
    "        y = y.view(-1, 1)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        batch_loss.append(loss.item())\n",
    "    loss_avg = sum(batch_loss) / len(batch_loss)\n",
    "\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20601c4d-aba5-47bc-b99a-1a48d82e7ae4",
   "metadata": {},
   "source": [
    "## Isolated Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5840aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 1.2270801067352295\n",
      "c2 1.5948263558935611\n",
      "c3 1.9564043635671788\n",
      "c4 1.2360392542261827\n",
      "c5 1.2223030749489279\n",
      "c6 1.304645813173718\n",
      "c7 1.6455158650875092\n",
      "c8 1.7426149504525321\n",
      "c9 1.584003562512605\n",
      "c10 1.264386817165043\n",
      "c11 1.1598445934218329\n",
      "c12 1.6015692738925709\n",
      "c13 1.9488079696893692\n",
      "c14 1.091790728625797\n",
      "c15 2.026768694983588\n",
      "c16 1.697183950079812\n",
      "c17 1.5474528356602317\n",
      "c18 2.4321875788948755\n",
      "c19 1.1305986809176067\n",
      "c20 1.3184901245178715\n",
      "c21 1.47362024208595\n",
      "c22 1.7676244378089905\n",
      "c23 1.1200449674025825\n",
      "c24 1.9297072578359533\n"
     ]
    }
   ],
   "source": [
    "for client in client_ids:\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True)\n",
    "    isolated_model_path = \"FLTrack/checkpt/isolated/epoch_250/batch256_client_\"+str(client)+\".pth\"\n",
    "    isolated_model =  ShallowNN(169)\n",
    "    isolated_model.load_state_dict(torch.load(isolated_model_path))\n",
    "    print(str(client), eval(isolated_model, loss_fn, val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8b171-f5cd-49af-a454-82bf4b572492",
   "metadata": {},
   "source": [
    "## Federated Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "64a6dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model = ShallowNN(features)\n",
    "global_model.load_state_dict(torch.load('FLTrack/checkpt/fedl/epoch_250/25_rounds_10_epochs_per_round/global_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67248f7f-12db-4b6b-a1ea-bd63b652caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 1.4377839334549443\n",
      "c2 1.5201152284094628\n",
      "c3 1.534032772887837\n",
      "c4 1.894552817470149\n",
      "c5 1.4621374151285957\n",
      "c6 1.4649371008078258\n",
      "c7 1.569283813238144\n",
      "c8 1.6277056523731777\n",
      "c9 2.0137493506721826\n",
      "c10 2.017547747363215\n",
      "c11 1.8707252805297439\n",
      "c12 1.6075116606319653\n",
      "c13 2.4495287388563156\n",
      "c14 1.612745804446084\n",
      "c15 1.6191439893510606\n",
      "c16 1.4485814571380615\n",
      "c17 1.6247947717967786\n",
      "c18 2.2577746998180044\n",
      "c19 1.7602314034173654\n",
      "c20 1.497902689441558\n",
      "c21 1.4542092660377766\n",
      "c22 2.5085608618600026\n",
      "c23 1.9216591612152432\n",
      "c24 1.6408439521436338\n"
     ]
    }
   ],
   "source": [
    "for client in client_ids:\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True)\n",
    "    print(str(client), eval(global_model, loss_fn, val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "26cae8e7-8628-442a-b37d-a59d7742f6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.671667</td>\n",
       "      <td>54.51113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_loss  validation_loss\n",
       "0      54.671667         54.51113"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"FLTrack/training_stats/fedl/fl_stats_epoch1_5/client_c1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761b18f",
   "metadata": {},
   "source": [
    "## Error Bars for Federated Learning vs Isolated Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac455aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = []\n",
    "for client in client_ids:\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True)\n",
    "    \n",
    "    isolated_model_path = \"checkpt/epoch_500/isolated/batch64_client_\"+str(client)+\".pth\"\n",
    "    isolated_model =  ShallowNN(features)\n",
    "    isolated_model.load_state_dict(torch.load(isolated_model_path))\n",
    "    \n",
    "    isolated_mae,(iso_lower_band, iso_upper_band), _  = evaluate_mae_with_confidence(isolated_model, val_loader)\n",
    "    federated_mae,(fed_lower_band, fed_upper_band), _ = evaluate_mae_with_confidence(global_model,val_loader)\n",
    "    \n",
    "    eval_dict = {\"client_id\":client, \"Isolated Average MAE\": round(isolated_mae, 4),\n",
    "                 \"Isolated MAE lower band\":round(iso_lower_band,4),\n",
    "                 \"Isolated MAE upper band\":round(iso_upper_band,4),\n",
    "                 \"Federated Average MAE\" :round(federated_mae, 4),\n",
    "                \"Federated MAE lower band\": round(fed_lower_band, 4),\n",
    "                \"Federated MAE upper band\":round(fed_upper_band,4)}\n",
    "    eval_list.append(eval_dict)\n",
    "    \n",
    "eval_df = pd.DataFrame.from_dict(eval_list)\n",
    "eval_df[\"clients\"] = [i for i in range(1,25)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "bar_width = 0.3\n",
    "index = eval_df.index\n",
    "\n",
    "bar1 = ax.bar(index - bar_width / 2, eval_df['Isolated Average MAE'], bar_width, yerr=[\n",
    "    (eval_df[\"Isolated Average MAE\"] - eval_df[\"Isolated MAE lower band\"]),\n",
    "    (eval_df['Isolated MAE upper band'] - eval_df[\"Isolated Average MAE\"])\n",
    "], capsize=5, label='Isolated Model MAE')\n",
    "\n",
    "bar2 = ax.bar(index + bar_width / 2, eval_df['Federated Average MAE'], bar_width, yerr=[\n",
    "    (eval_df[\"Federated Average MAE\"] - eval_df[\"Federated MAE lower band\"]),\n",
    "    (eval_df['Federated MAE upper band'] - eval_df[\"Federated Average MAE\"])\n",
    "], capsize=5, label='Federated Model MAE')\n",
    "\n",
    "ax.set_xlabel('Client IDs', fontdict={'fontsize': 13})\n",
    "ax.set_ylabel(\"Mean Absolute Error for Validation\", fontdict={'fontsize': 13})\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(eval_df['clients'])\n",
    "ax.legend(fontsize=15, loc=\"upper right\")\n",
    "\n",
    "# Adjust the xlim to decrease space at the left and right edges\n",
    "ax.set_xlim(index[0] - 0.7, index[-1] + 0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2cf62",
   "metadata": {},
   "source": [
    "## Influence with prediction difference at 500 global rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95700673",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_val = []\n",
    "for client in client_ids:\n",
    "    model = ShallowNN(features)\n",
    "    model.load_state_dict(torch.load('checkpt/epoch_500/influence/' + str(client)+ '_fedl_global_500.pth'))\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    inf = influence(global_model,model,val_set)\n",
    "    inf_val.append(round(inf.item(),4))\n",
    "   \n",
    "data = {\"client id\": client_ids, \"inf_val\": inf_val}\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv(\"insights/influence_with_pred_diff_ex1.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6f7c4",
   "metadata": {},
   "source": [
    "## Influence with prediction difference at 1 global round and 25 local rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cf202",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = ShallowNN(features)\n",
    "global_model.load_state_dict(torch.load('checkpt/saving/epoch_500/global_1/global_model.pth'))\n",
    "\n",
    "inf_val_test = []\n",
    "for client in client_ids:\n",
    "    model = ShallowNN(features)\n",
    "    model.load_state_dict(torch.load('checkpt/epoch_25/influence/1_rounds_25_epochs_per_round/' + str(client)+ '_fedl_global_1_25.pth'))\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    inf = influence(global_model,model,val_set)\n",
    "    inf_val_test.append(round(inf.item(),4))\n",
    "    \n",
    "data_test = {\"client id\": client_ids, \"inf_val\": inf_val_test}\n",
    "data_test = pd.DataFrame(data_test)\n",
    "data_test.to_csv(\"insights/influence_with_pred_diff_ex2.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345ea02",
   "metadata": {},
   "source": [
    "## Influence with mae at 1 global round and 25 local rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be237c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_inf = []\n",
    "for client in client_ids:\n",
    "    isolated_model = ShallowNN(features)\n",
    "    isolated_model.load_state_dict(torch.load('checkpt/epoch_500/influence/' + str(client)+ '_fedl_global_500.pth'))\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True)\n",
    "    \n",
    "    _, _ , isolated_mae = evaluate(isolated_model, val_loader, loss_fn)\n",
    "    _, _ , global_mae = evaluate(global_model,val_loader,loss_fn)\n",
    "    \n",
    "    inf = global_mae - isolated_mae\n",
    "    \n",
    "    performance_inf.append(round(inf.item(),4))\n",
    "\n",
    "data = {\"client id\": client_ids, \"inf_val\": performance_inf}\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv(\"insights/influence_with_mae_ex2.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5471d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Eccentricity  $\\xi^L$ \n",
    "\n",
    "$\n",
    "\\begin{equation}\\label{eq:Ecc1}\n",
    "\\xi_i = \\frac{2\\sum_{j=1}^{k}d(\\mathcal{H}_{\\mu_i}, \\mathcal{H}_{\\mu_j})}{\\sum_{l=1}^{k}\\sum _{j=1}^{k} d(\\mathcal{H}_{\\mu_l}, \\mathcal{H}_{\\mu_j})},\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Where  $\\mathcal{H}_{\\mu_i}$ is the Hessian matrix of client $i$, and $d(.,.)$ is the Euclidean distance between the Hessian matrices of two clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be124b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_matrix_dict = {\n",
    "        key: torch.load(\"hessians/epoch_500/iso/\" + str(key) + \".pth\")\n",
    "        for key in client_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdcbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecce_dict = hessian_eccentricity(local_matrix_dict, euclidean_distance)\n",
    "ecc_hessian = {\"client id\": client_ids, \"hess_ecc\": list(ecce_dict.values())}\n",
    "ecc_hessian = pd.DataFrame(ecc_hessian)\n",
    "ecc_hessian.to_csv(\"insights/eccentricity_with_hessian_euclidean_with_local_model.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187af1ff",
   "metadata": {},
   "source": [
    "## Eccentricity $\\xi^G$ \n",
    "\n",
    "$\n",
    "\\begin{equation}\\label{eq:Ecc1}\n",
    "\\xi_i = \\frac{2\\sum_{j=1}^{k}d(\\mathcal{H}^i_{\\mathcal M}, \\mathcal{H}^j_{\\mathcal M})}{\\sum_{l=1}^{k}\\sum _{j=1}^{k} d(\\mathcal{H}^l_{\\mathcal M}, \\mathcal{H}^j_{\\mathcal M})},\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "where $\\mathcal{H}^i_{\\mathcal M}$ is the Hessian matrix of client $i$, and $d(.,.)$ is the Euclidean distance between the Hessian matrices global with respect to the validation dataset of clients $i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_matrix_dict = {\n",
    "        key: torch.load(\"hessians/epoch_500/fed/\" + str(key) + \".pth\")\n",
    "        for key in client_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e62f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecce_dict_g = hessian_eccentricity(global_matrix_dict, euclidean_distance)\n",
    "ecc_hessian_g = {\"client id\": client_ids, \"hess_ecc\": list(ecce_dict_g.values())}\n",
    "ecc_hessian_g = pd.DataFrame(ecc_hessian)\n",
    "ecc_hessian_g.to_csv(\"insights/eccentricity_with_hessian_euclidean_with_globall_model.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6222ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.022619629561823677, 1.62271054254116, -0.5735217639598182, 0, -0.7876090943058588, 0, 0.43482986006497976, 1.6028013361292264, -0.10931628063829524, -0.6966764002778227, -0.17369175360870828, 0.16841961315934875, -0.015073389215806005, -0.4861588087040261, -0.06287855664828562, -0.23575240856089766, 0.07736005847409497, 0.7842280658106887, 0.12698984913067995, -0.08667967230145918, 0.15672320636514706, 0.13853950906135654, 0.7912020259738062, 0.6457963290841103]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
