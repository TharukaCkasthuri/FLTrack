{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4103d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import ShallowNN\n",
    "from utils import load_file, get_all_possible_pairs\n",
    "from evals import evaluate, pairwise_euclidean_distance , influence, layer_importance, layer_importance_bias, layerwise_full_accumulated_proximity\n",
    "from evals import euclidean_distance, pairwise_euclidean_distance, accumulated_proximity\n",
    "\n",
    "features = 197\n",
    "batch_size = 64\n",
    "loss_fn = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240fb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = [\"0_0\",\"0_1\",\"0_2\",\"0_3\",\"0_4\",\"0_5\",\"1_0\",\"1_1\",\"1_2\",\"1_3\",\"1_4\",\"1_5\",\"2_0\",\"2_1\",\"2_2\",\"2_3\",\"2_4\",\"2_5\",\"3_0\",\"3_1\",\"3_2\",\"3_3\",\"3_4\",\"3_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2ea6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclidean_distance(global_model.track_layers[\"layer_1\"].weight.data.view(1, -1),global_model.track_layers[\"layer_1\"].weight.data.view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce3e8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.load(\"checkpt/isolated/batch64_client_0_0.pth\")\n",
    "critarians = [item for item in dummy]\n",
    "state_dicts = {\n",
    "        key: torch.load(\"checkpt/isolated/batch64_client_\" + str(key) + \".pth\")\n",
    "        for key in client_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc90d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerwise_proximity(x:collections.OrderedDict,y:collections.OrderedDict, critarian:str , distance_matrix):\n",
    "    if critarian.split(\".\")[-1] == \"bias\":\n",
    "        proximity = accumulated_proximity(x[critarian].view(1, -1),y[critarian].view(1, -1),distance_matrix)\n",
    "    else:\n",
    "        proximity = accumulated_proximity(x[critarian],y[critarian],distance_matrix)\n",
    "    \n",
    "    return proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd4adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerwise_full_accumulated_proximity(\n",
    "    clients: list, criterian: str, distance_matrix) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate the layer-wise full accumulated proximity between all clients.\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "    clients: list; list of clients\n",
    "    criterian: str; criterian to be evaluated, basically the layer name.\n",
    "    distance_matrix: Callable; distance matrix\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    total_weight_proximity: float; total weight proximity\n",
    "    total_bias_proximity: float; total bias proximity\n",
    "    \"\"\"\n",
    "    state_dicts = {\n",
    "        key: torch.load(\"checkpt/isolated/batch64_client_\" + str(key) + \".pth\")\n",
    "        for key in clients\n",
    "    }\n",
    "\n",
    "    #possible_pairs = get_all_possible_pairs(clients)\n",
    "\n",
    "    total_proximity = 0.0\n",
    "\n",
    "    for l in clients:\n",
    "        for i in clients:\n",
    "            prox = layerwise_proximity(state_dicts[l],state_dicts[i],criterian, distance_matrix)\n",
    "            total_proximity += prox\n",
    "\n",
    "    return total_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ac2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prox_dict = {}\n",
    "for item in critarians:\n",
    "    full_prox_dict[item] = layerwise_full_accumulated_proximity(client_ids, item ,euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461bdc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1.weight': tensor(55107.3438),\n",
       " 'layer_1.bias': tensor(588.5198),\n",
       " 'layer_2.weight': tensor(25738.9277),\n",
       " 'layer_2.bias': tensor(395.0583),\n",
       " 'layer_3.weight': tensor(10944.6992),\n",
       " 'layer_3.bias': tensor(23.8015)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_prox_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1aa08",
   "metadata": {},
   "source": [
    "### Layer_1 Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa22d6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccentricities = {}\n",
    "for c in critarians:\n",
    "    client_ecc = {}\n",
    "    for client in client_ids:\n",
    "        client_matrix = torch.load(\"checkpt/isolated/batch64_client_\" + str(client) + \".pth\")\n",
    "        acc_proximity = 0.0\n",
    "        for key in state_dicts:\n",
    "            distance = layerwise_proximity(client_matrix,state_dicts[key],c, euclidean_distance)\n",
    "            acc_proximity += distance\n",
    "        eccentricity = 2*acc_proximity/full_prox_dict[c]\n",
    "        client_ecc[client] = eccentricity.item()\n",
    "    eccentricities[c] = client_ecc\n",
    "    #print(client,acc_proximity, 2*acc_proximity/layer1_fullweight_prox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abb2cdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_1.weight</th>\n",
       "      <th>layer_1.bias</th>\n",
       "      <th>layer_2.weight</th>\n",
       "      <th>layer_2.bias</th>\n",
       "      <th>layer_3.weight</th>\n",
       "      <th>layer_3.bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_0</th>\n",
       "      <td>0.084010</td>\n",
       "      <td>0.075930</td>\n",
       "      <td>0.083319</td>\n",
       "      <td>0.083742</td>\n",
       "      <td>0.085984</td>\n",
       "      <td>0.043081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_1</th>\n",
       "      <td>0.085182</td>\n",
       "      <td>0.074758</td>\n",
       "      <td>0.083903</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.088410</td>\n",
       "      <td>0.054493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_2</th>\n",
       "      <td>0.078688</td>\n",
       "      <td>0.070743</td>\n",
       "      <td>0.080501</td>\n",
       "      <td>0.074649</td>\n",
       "      <td>0.077790</td>\n",
       "      <td>0.100349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_3</th>\n",
       "      <td>0.079251</td>\n",
       "      <td>0.082931</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.069608</td>\n",
       "      <td>0.078640</td>\n",
       "      <td>0.110012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_4</th>\n",
       "      <td>0.075787</td>\n",
       "      <td>0.064629</td>\n",
       "      <td>0.079339</td>\n",
       "      <td>0.079195</td>\n",
       "      <td>0.075040</td>\n",
       "      <td>0.054656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer_1.weight  layer_1.bias  layer_2.weight  layer_2.bias  \\\n",
       "0_0        0.084010      0.075930        0.083319      0.083742   \n",
       "0_1        0.085182      0.074758        0.083903      0.082090   \n",
       "0_2        0.078688      0.070743        0.080501      0.074649   \n",
       "0_3        0.079251      0.082931        0.081003      0.069608   \n",
       "0_4        0.075787      0.064629        0.079339      0.079195   \n",
       "\n",
       "     layer_3.weight  layer_3.bias  \n",
       "0_0        0.085984      0.043081  \n",
       "0_1        0.088410      0.054493  \n",
       "0_2        0.077790      0.100349  \n",
       "0_3        0.078640      0.110012  \n",
       "0_4        0.075040      0.054656  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp_eccetricities = pd.DataFrame.from_dict(eccentricities)\n",
    "lrp_eccetricities.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f6f82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_1.weight</th>\n",
       "      <th>layer_1.bias</th>\n",
       "      <th>layer_2.weight</th>\n",
       "      <th>layer_2.bias</th>\n",
       "      <th>layer_3.weight</th>\n",
       "      <th>layer_3.bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_0</th>\n",
       "      <td>84.556248</td>\n",
       "      <td>0.743609</td>\n",
       "      <td>13.919749</td>\n",
       "      <td>0.376496</td>\n",
       "      <td>0.361039</td>\n",
       "      <td>0.042860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_1</th>\n",
       "      <td>80.643772</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>17.243428</td>\n",
       "      <td>0.596817</td>\n",
       "      <td>0.580415</td>\n",
       "      <td>0.085138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_2</th>\n",
       "      <td>83.195202</td>\n",
       "      <td>0.590558</td>\n",
       "      <td>15.128975</td>\n",
       "      <td>0.487478</td>\n",
       "      <td>0.531331</td>\n",
       "      <td>0.066456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_3</th>\n",
       "      <td>85.542781</td>\n",
       "      <td>0.613843</td>\n",
       "      <td>13.052207</td>\n",
       "      <td>0.351687</td>\n",
       "      <td>0.394934</td>\n",
       "      <td>0.044548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_4</th>\n",
       "      <td>84.022049</td>\n",
       "      <td>0.575856</td>\n",
       "      <td>14.383083</td>\n",
       "      <td>0.464949</td>\n",
       "      <td>0.489019</td>\n",
       "      <td>0.065044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     layer_1.weight  layer_1.bias  layer_2.weight  layer_2.bias  \\\n",
       "0_0       84.556248      0.743609       13.919749      0.376496   \n",
       "0_1       80.643772      0.850430       17.243428      0.596817   \n",
       "0_2       83.195202      0.590558       15.128975      0.487478   \n",
       "0_3       85.542781      0.613843       13.052207      0.351687   \n",
       "0_4       84.022049      0.575856       14.383083      0.464949   \n",
       "\n",
       "     layer_3.weight  layer_3.bias  \n",
       "0_0        0.361039      0.042860  \n",
       "0_1        0.580415      0.085138  \n",
       "0_2        0.531331      0.066456  \n",
       "0_3        0.394934      0.044548  \n",
       "0_4        0.489019      0.065044  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_importance_scores = {}\n",
    "  \n",
    "for client in client_ids:\n",
    "    iso_model = ShallowNN(features)\n",
    "    iso_model.load_state_dict(torch.load(\"checkpt/isolated/batch64_client_\" + str(client) + \".pth\"))\n",
    "    validation_data = torch.load(\"trainpt/\" + str(client) + \".pt\")\n",
    "    validation_data_loader = DataLoader(validation_data, batch_size, shuffle=True)\n",
    "    iso_layer_importance = layer_importance_bias(iso_model, loss_fn, validation_data_loader)\n",
    "    \n",
    "    layer_importance_scores[client] = iso_layer_importance\n",
    "layer_importance = pd.DataFrame.from_dict(layer_importance_scores).T\n",
    "layer_importance.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "569dbd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1.weight 2.0\n",
      "layer_im 81.5915705676305\n",
      "layer_1.bias 2.0\n",
      "layer_im 0.7569058531910482\n",
      "layer_2.weight 2.0\n",
      "layer_im 16.584087878674254\n",
      "layer_2.bias 2.0\n",
      "layer_im 0.5440387869220099\n",
      "layer_3.weight 2.0\n",
      "layer_im 0.46381884583326927\n",
      "layer_3.bias 2.0\n",
      "layer_im 0.05957806774891431\n"
     ]
    }
   ],
   "source": [
    "for item in critarians:\n",
    "    print(item, round(lrp_eccetricities[item].sum(),4))\n",
    "    print(\"layer_im\",layer_importance[item].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1d2516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_weight_ls = 81.60\n",
    "layer_1_bias_ls = 0.76\n",
    "layer_2_weight_ls = 16.57\n",
    "layer_2_bias_ls = 0.54\n",
    "layer_3_weight_ls = 0.47\n",
    "layer_3_bias_ls = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "615279f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = [] \n",
    "weighted_avg = []\n",
    "for index, client in lrp_eccetricities.iterrows():\n",
    "    avg = (client['layer_1.weight'] + client['layer_1.bias'] + client['layer_2.weight'] + client['layer_2.bias'] + client['layer_3.weight'] + client['layer_3.bias'])/6\n",
    "    weighted = (client['layer_1.weight']*layer_1_weight_ls + client['layer_1.bias']*layer_1_bias_ls + \n",
    "                client['layer_2.weight']*layer_2_weight_ls + client['layer_2.bias']*layer_2_bias_ls + \n",
    "                client['layer_3.weight']*layer_3_weight_ls + client['layer_3.bias']*layer_3_bias_ls)/(100)\n",
    "    averages.append(round(avg,4))\n",
    "    weighted_avg.append(round(weighted,4))\n",
    "lrp_eccetricities[\"average\"] = averages\n",
    "lrp_eccetricities[\"weighted_avg\"] = weighted_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a42e683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0_0    0.0838\n",
       "0_1    0.0849\n",
       "0_2    0.0789\n",
       "0_3    0.0795\n",
       "0_4    0.0763\n",
       "0_5    0.0855\n",
       "1_0    0.0859\n",
       "1_1    0.0848\n",
       "1_2    0.0865\n",
       "1_3    0.0837\n",
       "1_4    0.0875\n",
       "1_5    0.0923\n",
       "2_0    0.0772\n",
       "2_1    0.0783\n",
       "2_2    0.0788\n",
       "2_3    0.0789\n",
       "2_4    0.0780\n",
       "2_5    0.0781\n",
       "3_0    0.0873\n",
       "3_1    0.0873\n",
       "3_2    0.0851\n",
       "3_3    0.0868\n",
       "3_4    0.0867\n",
       "3_5    0.0879\n",
       "Name: weighted_avg, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp_eccetricities[\"weighted_avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65e80c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04185"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0837/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78a91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ba0f8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041666666666666664"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.08333333333333333/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c80bc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
