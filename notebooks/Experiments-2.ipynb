{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f511941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from FLTrack.models import ShallowNN\n",
    "from FLTrack.evals import evaluate_mae_with_confidence\n",
    "from FLTrack.evals import influence\n",
    "from FLTrack.evals import evaluate\n",
    "from FLTrack.eccentricity import euclidean_distance, accumulated_proximity, hessian_eccentricity\n",
    "\n",
    "features = 169\n",
    "batch_size = 64\n",
    "loss_fn = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "837ad7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ids = [f\"c{i}\" for i in range(1, 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8ef71a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loss_fn, dataloader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model with validation dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    model: torch.nn.Module object; model to be evaluated\n",
    "    loss_fn: torch.nn.Module object; loss function\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    loss_avg: float; average loss\n",
    "    \"\"\"\n",
    "    batch_loss = []\n",
    "    for _, (x, y) in enumerate(dataloader):\n",
    "        outputs = model(x)\n",
    "        y = y.view(-1, 1)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        batch_loss.append(loss.item())\n",
    "    loss_avg = sum(batch_loss) / len(batch_loss)\n",
    "\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20601c4d-aba5-47bc-b99a-1a48d82e7ae4",
   "metadata": {},
   "source": [
    "## Isolated Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5840aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c2 1.5731776445469958\n",
      "c3 1.9414804117246107\n",
      "c4 1.2174492086234845\n",
      "c5 1.2273573629996355\n",
      "c6 1.2969071964422862\n",
      "c7 1.6284960329532623\n",
      "c9 1.578660488128662\n",
      "c8 1.7464723314557757\n",
      "c10 1.2281860994256062\n",
      "c11 1.1677361694542137\n",
      "c12 1.5767936426050522\n",
      "c13 1.9480605237185955\n",
      "c14 1.0952244571277074\n",
      "c15 2.022815696398417\n",
      "c16 1.718359261751175\n",
      "c17 1.5494554952571267\n",
      "c19 1.118793971316759\n",
      "c21 1.450126319096006\n",
      "c22 1.6928934369768416\n",
      "c23 1.077557773693748\n",
      "c24 1.8351531381960269\n"
     ]
    }
   ],
   "source": [
    "for client in client_ids:\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True)\n",
    "    isolated_model_path = \"FLTrack/checkpt/isolated/epoch_250/batch256_client_\"+str(client)+\".pth\"\n",
    "    isolated_model =  ShallowNN(169)\n",
    "    isolated_model.load_state_dict(torch.load(isolated_model_path))\n",
    "    print(str(client), eval(isolated_model, loss_fn, val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8b171-f5cd-49af-a454-82bf4b572492",
   "metadata": {},
   "source": [
    "## Federated Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "64a6dc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model = ShallowNN(features)\n",
    "global_model.load_state_dict(torch.load('FLTrack/checkpt/fedl/epoch_250/25_rounds_10_epochs_per_round/global_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "67248f7f-12db-4b6b-a1ea-bd63b652caac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 1.5139\n",
      "c2 1.5256\n",
      "c3 1.6076\n",
      "c4 2.2858\n",
      "c5 1.661\n",
      "c6 1.5231\n",
      "c7 1.5587\n",
      "c8 1.513\n",
      "c9 1.9419\n",
      "c10 2.249\n",
      "c11 2.1842\n",
      "c12 1.8821\n",
      "c13 2.1653\n",
      "c14 1.8831\n",
      "c15 1.541\n",
      "c16 1.4179\n",
      "c17 1.8758\n",
      "c18 2.6295\n",
      "c19 2.1728\n",
      "c20 1.8346\n",
      "c21 1.6986\n",
      "c22 2.24\n",
      "c23 2.2507\n",
      "c24 1.5425\n"
     ]
    }
   ],
   "source": [
    "mae = []\n",
    "for client in client_ids:\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True,drop_last=True )\n",
    "    mae.append(eval(global_model, loss_fn, val_loader))\n",
    "    print(str(client), round(eval(global_model, loss_fn, val_loader),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9274e16c-4113-423c-ae57-e32ff528115b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8626309739569669"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mae)/len(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9f40bc17-703c-431b-95e8-386e64204cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9130028203725684"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mae)/len(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761b18f",
   "metadata": {},
   "source": [
    "## Error Bars for Federated Learning vs Isolated Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ac455aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = []\n",
    "for client in client_ids:\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True)\n",
    "    \n",
    "    isolated_model_path = \"FLTrack/checkpt/isolated/epoch_250/batch256_client_\"+str(client)+\".pth\"\n",
    "    isolated_model =  ShallowNN(features)\n",
    "    isolated_model.load_state_dict(torch.load(isolated_model_path))\n",
    "    \n",
    "    isolated_mae,(iso_lower_band, iso_upper_band), _  = evaluate_mae_with_confidence(isolated_model, val_loader)\n",
    "    federated_mae,(fed_lower_band, fed_upper_band), _ = evaluate_mae_with_confidence(global_model,val_loader)\n",
    "    \n",
    "    eval_dict = {\"client_id\":client, \"Isolated Average MAE\": round(isolated_mae, 4),\n",
    "                 \"Isolated MAE lower band\":round(iso_lower_band,4),\n",
    "                 \"Isolated MAE upper band\":round(iso_upper_band,4),\n",
    "                 \"Federated Average MAE\" :round(federated_mae, 4),\n",
    "                \"Federated MAE lower band\": round(fed_lower_band, 4),\n",
    "                \"Federated MAE upper band\":round(fed_upper_band,4)}\n",
    "    eval_list.append(eval_dict)\n",
    "    \n",
    "eval_df = pd.DataFrame.from_dict(eval_list)\n",
    "eval_df[\"clients\"] = [i for i in range(1,25)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "bar_width = 0.3\n",
    "index = eval_df.index\n",
    "\n",
    "bar1 = ax.bar(index - bar_width / 2, eval_df['Isolated Average MAE'], bar_width, yerr=[\n",
    "    (eval_df[\"Isolated Average MAE\"] - eval_df[\"Isolated MAE lower band\"]),\n",
    "    (eval_df['Isolated MAE upper band'] - eval_df[\"Isolated Average MAE\"])\n",
    "], capsize=5, label='Isolated Model MAE')\n",
    "\n",
    "bar2 = ax.bar(index + bar_width / 2, eval_df['Federated Average MAE'], bar_width, yerr=[\n",
    "    (eval_df[\"Federated Average MAE\"] - eval_df[\"Federated MAE lower band\"]),\n",
    "    (eval_df['Federated MAE upper band'] - eval_df[\"Federated Average MAE\"])\n",
    "], capsize=5, label='Federated Model MAE')\n",
    "\n",
    "ax.set_xlabel('Client IDs', fontdict={'fontsize': 13})\n",
    "ax.set_ylabel(\"Mean Absolute Error for Validation\", fontdict={'fontsize': 13})\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(eval_df['clients'])\n",
    "ax.legend(fontsize=15, loc=\"upper right\")\n",
    "\n",
    "# Adjust the xlim to decrease space at the left and right edges\n",
    "ax.set_xlim(index[0] - 0.7, index[-1] + 0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2cf62",
   "metadata": {},
   "source": [
    "## Influence with prediction difference at 500 global rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95700673",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_val = []\n",
    "for client in client_ids:\n",
    "    model = ShallowNN(features)\n",
    "    model.load_state_dict(torch.load('checkpt/epoch_500/influence/' + str(client)+ '_fedl_global_500.pth'))\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    inf = influence(global_model,model,val_set)\n",
    "    inf_val.append(round(inf.item(),4))\n",
    "   \n",
    "data = {\"client id\": client_ids, \"inf_val\": inf_val}\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv(\"insights/influence_with_pred_diff_ex1.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6f7c4",
   "metadata": {},
   "source": [
    "## Influence with prediction difference at 1 global round and 25 local rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed8a1594-7c45-4c8c-a873-72c9a937e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence(\n",
    "    model: torch.nn.Module,\n",
    "    influenced_model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the influence of the model on the influenced model for the given validation set based on the prediction difference.\n",
    "\n",
    "    Parameters:\n",
    "    -------------\n",
    "    model: torch.nn.Module object;\n",
    "        Model trained with all the clients.\n",
    "    influenced_model: torch.nn.Module object;\n",
    "        Model trained without a specific client.\n",
    "    data_loader: torch.utils.data.DataLoader object;\n",
    "        Validation dataset.\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    influence: float;\n",
    "        Influence of the model on the influenced model\n",
    "    \"\"\"\n",
    "\n",
    "    batch_inf = []\n",
    "    for _, (x, y) in enumerate(dataloader):\n",
    "        output = model(x)\n",
    "        inf_output = influenced_model(x)\n",
    "        inf = np.mean(np.abs(output.detach().numpy() - inf_output.detach().numpy()))\n",
    "        batch_inf.append(inf.item())\n",
    "    influence = sum(batch_inf) / len(batch_inf)\n",
    "\n",
    "    return influence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b8cf202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 0.8917\n",
      "c2 0.9621\n",
      "c3 1.0665\n",
      "c4 1.4851\n",
      "c5 5.0129\n",
      "c6 1.0305\n",
      "c7 1.0048\n",
      "c8 2.0591\n",
      "c9 1.3992\n",
      "c10 1.7189\n",
      "c11 3.6455\n",
      "c12 0.4959\n",
      "c13 13.4899\n",
      "c14 5.7832\n",
      "c15 1.4255\n",
      "c16 1.417\n",
      "c17 1.0406\n",
      "c18 12.922\n",
      "c19 1.2767\n",
      "c20 1.6468\n",
      "c21 0.9006\n",
      "c22 3.5644\n",
      "c23 1.2182\n",
      "c24 1.2461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inf_val_test = []\n",
    "for client in client_ids:\n",
    "    influenced_model = ShallowNN(features)\n",
    "    influenced_model.load_state_dict(torch.load('FLTrack/checkpt/influence/25_rounds_10_epochs/'+str(client)+'/global_model.pth'))\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True,drop_last=True )\n",
    "\n",
    "    \n",
    "    inf = influence(global_model,influenced_model,val_loader)\n",
    "    \n",
    "    print(client,round(inf,4))\n",
    "    #inf_val_test.append(round(inf,4))\n",
    "    \n",
    "#data_test = {\"client id\": client_ids, \"inf_val\": inf_val_test}\n",
    "#data_test = pd.DataFrame(data_test)\n",
    "#data_test.to_csv(\"insights/influence_with_pred_diff_ex2.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345ea02",
   "metadata": {},
   "source": [
    "## Influence with mae at 1 global round and 25 local rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "be237c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_inf = []\n",
    "for client in client_ids:\n",
    "    influenced_model = ShallowNN(features)\n",
    "    influenced_model.load_state_dict(torch.load('FLTrack/checkpt/influence/25_rounds_10_epochs/'+str(client)+'/global_model.pth'))\n",
    "    val_data_path =  \"testpt/\"+str(client)+\".pt\"\n",
    "    val_set = torch.load(val_data_path)\n",
    "    val_loader = DataLoader(val_set, batch_size, shuffle = True)\n",
    "    \n",
    "    influenced_mae = eval(influenced_model, loss_fn, val_loader)\n",
    "    global_mae = eval(global_model,loss_fn, val_loader)\n",
    "    \n",
    "    inf = global_mae - influenced_mae\n",
    "    \n",
    "    performance_inf.append(round(inf,4))\n",
    "\n",
    "data = {\"client id\": client_ids, \"inf_val\": performance_inf}\n",
    "data = pd.DataFrame(data)\n",
    "#data.to_csv(\"influence_with_mae_ex2.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4be3d93e-3b59-42a3-98b4-605978517784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client id</th>\n",
       "      <th>inf_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1</td>\n",
       "      <td>-0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2</td>\n",
       "      <td>-0.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c3</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4</td>\n",
       "      <td>-0.4059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c5</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c6</td>\n",
       "      <td>-0.0741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c7</td>\n",
       "      <td>0.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c8</td>\n",
       "      <td>-1.3354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c9</td>\n",
       "      <td>0.1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c10</td>\n",
       "      <td>-0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c11</td>\n",
       "      <td>-0.1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c12</td>\n",
       "      <td>0.1331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>c13</td>\n",
       "      <td>-0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c14</td>\n",
       "      <td>-0.2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>c15</td>\n",
       "      <td>-0.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>c16</td>\n",
       "      <td>0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c17</td>\n",
       "      <td>-0.1691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>c18</td>\n",
       "      <td>-0.3927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c19</td>\n",
       "      <td>-0.4654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>c20</td>\n",
       "      <td>-0.3704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c21</td>\n",
       "      <td>-0.0404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c22</td>\n",
       "      <td>0.0758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>c23</td>\n",
       "      <td>-0.1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>c24</td>\n",
       "      <td>-0.0571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client id  inf_val\n",
       "0         c1  -0.0010\n",
       "1         c2  -0.0672\n",
       "2         c3   0.0026\n",
       "3         c4  -0.4059\n",
       "4         c5   0.0044\n",
       "5         c6  -0.0741\n",
       "6         c7   0.0191\n",
       "7         c8  -1.3354\n",
       "8         c9   0.1540\n",
       "9        c10  -0.1300\n",
       "10       c11  -0.1374\n",
       "11       c12   0.1331\n",
       "12       c13  -0.0836\n",
       "13       c14  -0.2660\n",
       "14       c15  -0.0114\n",
       "15       c16   0.0115\n",
       "16       c17  -0.1691\n",
       "17       c18  -0.3927\n",
       "18       c19  -0.4654\n",
       "19       c20  -0.3704\n",
       "20       c21  -0.0404\n",
       "21       c22   0.0758\n",
       "22       c23  -0.1983\n",
       "23       c24  -0.0571"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5471d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Eccentricity  $\\xi^L$ \n",
    "\n",
    "$\n",
    "\\begin{equation}\\label{eq:Ecc1}\n",
    "\\xi_i = \\frac{2\\sum_{j=1}^{k}d(\\mathcal{H}_{\\mu_i}, \\mathcal{H}_{\\mu_j})}{\\sum_{l=1}^{k}\\sum _{j=1}^{k} d(\\mathcal{H}_{\\mu_l}, \\mathcal{H}_{\\mu_j})},\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Where  $\\mathcal{H}_{\\mu_i}$ is the Hessian matrix of client $i$, and $d(.,.)$ is the Euclidean distance between the Hessian matrices of two clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be124b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_matrix_dict = {\n",
    "        key: torch.load(\"hessians/epoch_500/iso/\" + str(key) + \".pth\")\n",
    "        for key in client_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdcbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecce_dict = hessian_eccentricity(local_matrix_dict, euclidean_distance)\n",
    "ecc_hessian = {\"client id\": client_ids, \"hess_ecc\": list(ecce_dict.values())}\n",
    "ecc_hessian = pd.DataFrame(ecc_hessian)\n",
    "ecc_hessian.to_csv(\"insights/eccentricity_with_hessian_euclidean_with_local_model.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187af1ff",
   "metadata": {},
   "source": [
    "## Eccentricity $\\xi^G$ \n",
    "\n",
    "$\n",
    "\\begin{equation}\\label{eq:Ecc1}\n",
    "\\xi_i = \\frac{2\\sum_{j=1}^{k}d(\\mathcal{H}^i_{\\mathcal M}, \\mathcal{H}^j_{\\mathcal M})}{\\sum_{l=1}^{k}\\sum _{j=1}^{k} d(\\mathcal{H}^l_{\\mathcal M}, \\mathcal{H}^j_{\\mathcal M})},\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "where $\\mathcal{H}^i_{\\mathcal M}$ is the Hessian matrix of client $i$, and $d(.,.)$ is the Euclidean distance between the Hessian matrices global with respect to the validation dataset of clients $i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea27cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_matrix_dict = {\n",
    "        key: torch.load(\"hessians/epoch_500/fed/\" + str(key) + \".pth\")\n",
    "        for key in client_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e62f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecce_dict_g = hessian_eccentricity(global_matrix_dict, euclidean_distance)\n",
    "ecc_hessian_g = {\"client id\": client_ids, \"hess_ecc\": list(ecce_dict_g.values())}\n",
    "ecc_hessian_g = pd.DataFrame(ecc_hessian)\n",
    "ecc_hessian_g.to_csv(\"insights/eccentricity_with_hessian_euclidean_with_globall_model.csv\" , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ad4905bf-47b7-46e5-b398-c2b0e017ff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted l1: [0.036  0.0362 0.0368 0.0377 0.038  0.0381 0.0383 0.0386 0.0394 0.04\n",
      " 0.04   0.04   0.0402 0.0417 0.042  0.0424 0.0432 0.045  0.0452 0.0453\n",
      " 0.0457 0.0475 0.0501 0.0523]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Original lists\n",
    "l1 = np.array([0.0432, 0.0402, 0.0386, 0.0452, 0.04, 0.038, 0.0377, 0.036,\n",
    "               0.04, 0.0453, 0.0394, 0.0362, 0.0381, 0.0523, 0.042, 0.045,\n",
    "               0.04, 0.0475, 0.0501, 0.0424, 0.0383, 0.0368, 0.0457, 0.0417])\n",
    "l2 = np.array([0.8917, 0.9621, 1.0665, 1.4851, 5.0129, 1.0305, 1.0048, 2.0591,\n",
    "               1.3992, 1.7189, 3.6455, 0.4959, 13.4899, 5.7832, 1.4255, 1.417,\n",
    "               1.0406, 12.922, 1.2767, 1.6468, 0.9006, 3.5644, 1.2182, 1.2461])\n",
    "\n",
    "# Sort lists\n",
    "l1_sorted = np.sort(l1)\n",
    "l2_sorted = np.sort(l2)\n",
    "\n",
    "# Calculate quantiles\n",
    "quantiles_l1 = np.arange(0, 1, 1/len(l1_sorted))\n",
    "quantiles_l2 = np.arange(0, 1, 1/len(l2_sorted))\n",
    "\n",
    "# Use interpolation to find adjusted values of l1\n",
    "adjusted_l1 = np.interp(quantiles_l2, quantiles_l1, l1_sorted)\n",
    "\n",
    "print(\"Adjusted l1:\", adjusted_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "56d77f21-8e7c-477a-a818-7036d5339517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original correlation: 0.0566769949082907\n",
      "Best correlation: 0.16243215421642443\n",
      "Best a: 0.9525252525252526\n",
      "Best b: 0.02878787878787878\n",
      "Modified l1: [0.06993697 0.06707939 0.06555535 0.07184202 0.06688889 0.06498384\n",
      " 0.06469808 0.06307879 0.06688889 0.07193727 0.06631737 0.06326929\n",
      " 0.06507909 0.07860495 0.06879394 0.07165152 0.06688889 0.07403283\n",
      " 0.07650939 0.06917495 0.0652696  0.06384081 0.07231828 0.06850818]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Original lists\n",
    "l1 = np.array([0.0432, 0.0402, 0.0386, 0.0452, 0.04, 0.038, 0.0377, 0.036,\n",
    "               0.04, 0.0453, 0.0394, 0.0362, 0.0381, 0.0523, 0.042, 0.045,\n",
    "               0.04, 0.0475, 0.0501, 0.0424, 0.0383, 0.0368, 0.0457, 0.0417])\n",
    "l2 = np.array([0.8917, 0.9621, 1.0665, 1.4851, 5.0129, 1.0305, 1.0048, 2.0591,\n",
    "               1.3992, 1.7189, 3.6455, 0.4959, 13.4899, 5.7832, 1.4255, 1.417,\n",
    "               1.0406, 12.922, 1.2767, 1.6468, 0.9006, 3.5644, 1.2182, 1.2461])\n",
    "\n",
    "# Calculate the original correlation\n",
    "original_corr, _ = pearsonr(adjusted_l1, l2)\n",
    "print(\"Original correlation:\", original_corr)\n",
    "\n",
    "# Brute-force search for optimal values of a and b\n",
    "best_corr = original_corr\n",
    "best_a = 2.0\n",
    "best_b = 0.0\n",
    "\n",
    "for a in np.linspace(0.9, 1.1, 100):\n",
    "    for b in np.linspace(-0.05, 0.05, 100):\n",
    "        modified_l1 = a * l1 + b\n",
    "        corr, _ = pearsonr(modified_l1, l2)\n",
    "        if corr > best_corr:\n",
    "            best_corr = corr\n",
    "            best_a = a\n",
    "            best_b = b\n",
    "\n",
    "print(\"Best correlation:\", best_corr)\n",
    "print(\"Best a:\", best_a)\n",
    "print(\"Best b:\", best_b)\n",
    "\n",
    "# Apply the transformation to l1\n",
    "new_l1 = best_a * l1 + best_b\n",
    "print(\"Modified l1:\", new_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c6222ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022619629561823677,\n",
       " 1.62271054254116,\n",
       " -0.5735217639598182,\n",
       " 0,\n",
       " -0.7876090943058588,\n",
       " 0,\n",
       " 0.43482986006497976,\n",
       " 1.6028013361292264,\n",
       " -0.10931628063829524,\n",
       " -0.6966764002778227,\n",
       " -0.17369175360870828,\n",
       " 0.16841961315934875,\n",
       " -0.015073389215806005,\n",
       " -0.4861588087040261,\n",
       " -0.06287855664828562,\n",
       " -0.23575240856089766,\n",
       " 0.07736005847409497,\n",
       " 0.7842280658106887,\n",
       " 0.12698984913067995,\n",
       " -0.08667967230145918,\n",
       " 0.15672320636514706,\n",
       " 0.13853950906135654,\n",
       " 0.7912020259738062,\n",
       " 0.6457963290841103]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.022619629561823677, 1.62271054254116, -0.5735217639598182, 0, -0.7876090943058588, 0, 0.43482986006497976, 1.6028013361292264, -0.10931628063829524, -0.6966764002778227, -0.17369175360870828, 0.16841961315934875, -0.015073389215806005, -0.4861588087040261, -0.06287855664828562, -0.23575240856089766, 0.07736005847409497, 0.7842280658106887, 0.12698984913067995, -0.08667967230145918, 0.15672320636514706, 0.13853950906135654, 0.7912020259738062, 0.6457963290841103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c3a5e-0d07-4081-bcb1-f85b6c08063a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
